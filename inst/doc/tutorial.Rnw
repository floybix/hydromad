\documentclass[11pt,a4paper]{article}
\pagestyle{headings}
%% link style
\usepackage{hyperref,color}
\definecolor{Red}{rgb}{0.5,0,0}
\definecolor{Blue}{rgb}{0,0,0.5}
  \hypersetup{%
    hyperindex = {true},
    colorlinks = {true},
    linktocpage = {true},
    plainpages = {false},
    linkcolor = {Blue},
    citecolor = {Blue},
    urlcolor = {Red},
    pdfstartview = {FitH},
    pdfpagemode = {UseOutlines},
    pdfview = {XYZ null null null}
  }
%% custom markup
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\let\code=\texttt
\let\proglang=\textsf
\def\ihacres{\textsc{ihacres}}
\def\Ihacres{\textsc{Ihacres}}
%% box the figures
\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}

\title{Hydromad Tutorial}
\author{Felix Andrews\\The Australian National University}

%\VignetteIndexEntry{Getting started, reading in data and fitting a model}
%\VignettePackage{hydromad}

\begin{document}

\SweaveOpts{engine=R,eps=FALSE,echo=FALSE,prefix.string=figs/tutorial}

<<preliminaries, echo=FALSE, results=hide>>=
if (!file.exists("figs")) dir.create("figs")
library(hydromad)
library(xtable)
ltheme <- canonical.theme("pdf")
ltheme$strip.background$col <- grey(7/8)
ltheme$strip.shingle$col <- grey(6/8)
ltheme$fontsize = list(text = 11)
lattice.options(default.theme = ltheme) ## set as default
ps.options(pointsize = 11)
options(width = 60, continue = " ", digits = 3)
set.seed(0)
@

\maketitle

\section{Introduction}

The \pkg{hydromad} package is designed for hydrological modelling and
associated data analysis. It is focussed on a \emph{top-down},
spatially lumped, empirical approach to environmental hydrology.
In practice the emphasis is on models of rainfall runoff in
catchments (watersheds). Such models predict streamflow from time
series of (areal) rainfall and temperature or potential
evapo-transpiration. They can be calibrated to time series of observed
data.

This tutorial describes how to get started with the \pkg{hydromad}
\proglang{R} package. It covers the basics of reading data in from
files, converting it into the appropriate format, and fitting and
analysing an \ihacres{} model.

The example we will look at is
the Cotter River catchment at Gingera (gauge 410730) in the
Australian Capital Territory, Australia. This is a 148 km$^2$ catchment
managed for urban water supply. Areal rainfall was estimated from
several rain gauges operated by the Bureau of Meteorology and
EcoWise. The temperature records come from Canberra Airport.

Once you have \proglang{R}
running\footnote{A Windows \proglang{R} installer is available from
  \url{http://cran.ms.unimelb.edu.au/bin/windows/base/release.htm}}
and have installed the \pkg{hydromad} package\footnote{at this pre-beta
development stage, you will need to ask Felix how to do this.}, you
can load it:
<<load-package, echo=TRUE>>=
library(hydromad)
@

\section{Input data}

The required input data files for this tutorial are included with the
\pkg{hydromad} package, in the \code{doc} directory. Note that the
processed data is available directly in \proglang{R} -- just type
\code{data(Cotter)} -- but we will read it from text files as an
exercise. If you already know how to import and handle time series in
R, you could skip this section.

A few simple
steps are required to import and convert the data into a usable form:
extracting dates from the files, converting streamflow
from ML/day to mm/day, handling missing data values, and aligning the
three time series in a common time period.

Let's first view the content of one of the input files.
Set the working directory to where the data file is:
<<view-files, echo=TRUE, eval=FALSE>>=
setwd(system.file("doc", package = "hydromad"))
file.show("pq_cotter.csv")
@
<<view-files-script, echo=FALSE>>=
cat(readLines("pq_cotter.csv", n = 5), "...", sep = "\n")
@

There is no header in the file, but we know that the columns
represent rainfall (P), streamflow (Q) and date of
observation. The temperature file is similar. Knowing the format and
columns we can use \code{read.table} to import the data:
<<read-files, echo=TRUE>>=
## rain and flow data
pqdat <- read.table("pq_cotter.csv", sep = ",",
                    col.names = c("P", "Q", "Date"), as.is = TRUE)
## temperature data
tdat <- read.table("t_cotter.csv", sep = ",",
                   col.names = c("T", "Date"), as.is = TRUE)
@
and view the structure of the resulting data frames:
<<view-str, echo=TRUE>>=
str(pqdat)
str(tdat)
@

So far, the \code{Date} columns are only text; \proglang{R} does not
know they are dates. We need to specify the date format, where
\code{\%d} is day, \code{\%m} is month number,
\code{\%b} is month name, \code{\%Y} is four-digit year and \code{\%y}
is two-digit year (see \code{?strptime}).
<<convert-dates, echo=TRUE>>=
pqdat$Date <- as.Date(pqdat$Date, "%d/%m/%Y")
tdat$Date <- as.Date(tdat$Date, "%d/%m/%Y")
@

If the day, month and year were in separate columns of the file, with
names \code{"day"}, \code{"mon"} and \code{"yr"} then you would do
something like:
<<convert-dates-from-columns, echo=TRUE, eval=FALSE>>=
pqdat$Date <- with(pqdat, as.Date(ISOdate(yr, mon, day)))
@

Negative values (-99) in the \emph{pq}
input file represent missing data; in \proglang{R} they should be set
to the special value \code{NA}.
Also, some dates in the temperature file are blank, and need to be
removed.
<<missing-values, echo=TRUE>>=
pqdat$P[pqdat$P < 0] <- NA
pqdat$Q[pqdat$Q < 0] <- NA
tdat <- subset(tdat, !is.na(Date))
@

The \pkg{hydromad} model fitting functions require that rainfall and streamflow are given in
the same units, typically mm / day. The streamflow data in our input
file is measured in ML / day, so we need to convert it, supplying the
catchment area of 148 km$^2$.
<<convert-to-mm, echo=TRUE>>=
pqdat$Q <- convertFlow(pqdat$Q, from = "ML", area.km2 = 148)
@

For simple applications, when the data series are already
synchronised, this data frame (or matrix) format may be enough.
However, there are benefits in working with actual \emph{time series}
objects: because they handle observation times, they allow
powerful merging, treatment of missing values, rolling averages
and other functions. While \proglang{R} has a built-in structure for
regular time series (\code{ts}), these do not handle specific dates or
times, only index numbers. It is recommended to work with
\code{zoo} objects (using the \pkg{zoo} package).\footnote{\pkg{zoo}
  objects are a generalisation of \code{ts} objects and in many cases
  can be used in the same way; see \code{vignette("zoo")}.}

<<zoo-objects, echo=TRUE>>=
library(zoo)
tsPQ <- zoo(pqdat[,1:2], pqdat$Date, frequency = 1)
tsT <- zoo(tdat[,1], tdat$Date, frequency = 1)
@

We can now merge the time series together into a final dataset.
Note that the \pkg{hydromad} package
expects temperature or evapo-transpiration data to be called \code{E},
not \code{T}.\footnote{This avoids name conflicts since in \proglang{R},
\code{T} is a shorthand for \code{TRUE}.}
<<zoo-merge, echo=TRUE>>=
Cotter <- merge(tsPQ, E = tsT, all = FALSE)
@

Print the first few rows (the \emph{head}) of the time series, to
check that everything looks OK:

<<zoo-head, echo=TRUE>>=
head(Cotter, 6)
range(time(Cotter))
@

This shows that the rainfall data has missing values at the
beginning. At the other end of the series, Streamflow data is missing.
This will not cause a problem, but let us tidy it up anyway: 

<<zoo-na-trim, echo=TRUE>>=
Cotter <- na.trim(Cotter)
@

The final dataset extends from \Sexpr{start(Cotter)} to
\Sexpr{end(Cotter)}, and is shown in Figure \ref{fig:dataplot} and
Table \ref{tab:datasumm}:

<<datasummary-code, echo=TRUE, eval=FALSE>>=
summary(Cotter)
@

<<datasummary, results=tex>>=
summ <- numericSummary(Cotter)
xtable(summ, caption="Data summary.
P = precipitation (mm/day), E = temperature (deg. C), Q = streamflow (mm/day).",
	label="tab:datasumm")
@


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot the raw (daily) time series:}
<<rawdataplot-code, echo=TRUE, eval=FALSE>>=
xyplot(Cotter)
@
  \emph{To plot a section of the time series:}
<<rawdataplot-code, echo=TRUE, eval=FALSE>>=
xyplot(Cotter, xlim = as.Date(c("1974-01-01","1975-01-01")))
@
  \emph{And to plot the time series aggregated to a monthly time step:}
<<dataplot-code, echo=TRUE, results=hide>>=
monthlyPQE <- aggregate(Cotter, as.yearmon, mean)
xyplot(monthlyPQE,
       screens = c("Streamflow (mm/day)", "Areal rain (mm/day)", "Temperature (deg. C)"),
       xlab = NULL)
@
<<dataplot, fig=TRUE, width=6, height=5>>=
print(trellis.last.object())
rm(monthlyPQE)
@
\caption{\label{fig:dataplot} Input data, averaged over months. }
\end{center}
\end{figure}


\section{Data checking}

In a real data analysis problem, data checking is a central
issue. However, as this document aims to introduce the core modelling
functions, only one simple check will be demonstrated here. 

Table \ref{tab:datasumm} shows the mean and quartiles of each input
data series. One measure that is of key interest in hydrology is the
\emph{runoff ratio}, the proportion of the rainfall which flows
out of the catchment. In a simple case this is just \code{sum(Q) /
  sum(P)}, but as we have missing values, we should only compare the
common observations:

<<runoff-ratio, echo=TRUE>>=
ok <- complete.cases(Cotter[,1:2])
with(Cotter, sum(Q[ok]) / sum(P[ok]))
@ 

This figure is within the range we would expect, so we probably have
the right data series and units.

See \code{vignette("dataChecking", package = "hydromad")} 
(\emph{under construction}) for more on this topic, including
analysing changes in the runoff ratio over time, and changes in
cross correlation over time.


\section{Calibration Periods}

Let us define some calibration periods. The streamflow in each of
these periods is shown in Figure \ref{fig:calperiodsplot}.
<<define-periods, echo=TRUE>>=
ts70s <- window(Cotter, start = "1970-01-01", end = "1979-12-31")
ts80s <- window(Cotter, start = "1980-01-01", end = "1989-12-31")
ts90s <- window(Cotter, start = "1990-01-01", end = "1999-12-31")
@

\begin{figure}[hpbt]
\begin{center}
  \emph{To plot one streamflow period:}
<<oneperiodplot-code, echo=TRUE, eval=FALSE>>=
xyplot(ts90s$Q)
@
  \emph{To plot log-transformed streamflow in one period:}
<<oneperiodlogplot-code, echo=TRUE, eval=FALSE>>=
xyplot(log10(ts90s$Q), type = c("l","g"))
@
  \emph{And to plot multiple periods on log scale:}
<<calperiodsplot-code, echo=TRUE, results=hide>>=
#cuts <- as.Date(c("1970-01-01", "1980-01-01",
#                  "1990-01-01", "2000-01-01"))
#dates <- time(Cotter)
#Q <- coredata(Cotter$Q)
#xyplot(Q ~ dates | cut(dates, cuts), type = c("l", "g"),
#       scales = list(x = "sliced", y = list(log = TRUE)),
#       layout = c(1, 3))
xyplot(list(the70s = ts70s$Q, the80s = ts80s$Q, the90s = ts90s$Q),
       scales = list(y = list(log = TRUE)), type = c("l", "g"),
       layout = c(1,3))
@
<<calperiodsplot, fig=TRUE, height=8>>=
print(trellis.last.object())
@
\caption{\label{fig:calperiodsplot} Streamflow data in each of the
  chosen calibration periods. }
\end{center}
\end{figure}

In the next section, a model will be fitted to the data in one calibration
period. It will then be applied to the other periods to
cross-check model performance.


\section{Model Calibration}

An \ihacres{} CWI model (Catchment Wetness Index, also known as the
\emph{Classic} version) will be fitted to 

A \code{hydromad} object encapsulates the chosen model form, parameter
values (or ranges of values), as well as results. The model form is
divided into two components: SMA (Soil Moisture Accounting) and
routing. Additionally, a specification can be given for fitting the
routing component (\code{rfit}). If given, this is applied
automatically to fit the routing component after the SMA parameters
have been specified. 

When we first set up the model, most of the parameters are not
uniquely specified, but rather have a range of possible values. These
defaults are taken from \code{hydromad.options()}, and they can be
over-ridden by arguments to the \code{hydromad} function.

A good starting point is the simple \ihacres{} model of
\cite{JakemanHornberger:1993}, which is a Soil Moisture Accounting
model referred to as \code{cwi} (Catchment Wetness Index\footnote{also known as the
\emph{Classic} version of \ihacres{}.}). The routing component is a
Unit Hydrograph composed of exponential components, which is referred
to as \code{expuh}.



<<model, echo=TRUE>>=
cotterMod <- hydromad(ts90s, sma = "cwi", routing = "expuh")
print(cotterMod)
@

With this model specification, we can choose to calibrate the model
is various ways, or to simulate from the specified parameter space, or
to run sensitivity or uncertainty analysis.

Currently implemented calibration methods include simple sampling schemes
(\code{fitBySampling}), Newton and Simplex methods with multistart or
presampling (\code{fitByOptim}) and the more sophisticated Shuffled
Complex Evolution (\code{fitBySCE}) and Differential Evolution
(\code{fitByDE}) methods. 

The objective function can be specified as the
\code{objective} argument to these functions, or by setting
\code{hydromad.options(objective = )}.
It is given as an R formula (a chunk of \proglang{R} code) based on
the values \code{Q} and \code{X}, representing observed and modelled
flow, respectively\footnote{The objective function can also refer to
  \code{U}, modelled effective rainfall.}.

Here we use the default, which is a weighted sum of the $R^2$ of
square-root transformed data, and the relative bias:
<<obj-fun>>=
hydromad.getOption("objective")
@

The \code{fitStat} function implements a generalisation
of the familiar $R^2$ (coefficient of determination) statistic.
The exponent applied to the equation is specied as argument \code{p},
so if \code{p = 2}, as it is by default, then it is indeed $R^2$:

\begin{equation}
  \mathrm{fitStat} = 1 - \frac{ \sum |Q_* - X_*|^p }{ \sum |Q_* - \mathrm{E}(Q_*)|^p }
\end{equation}

where $Q$ and $X$ are the observed and modelled values. Subscript $*$
denotes transformed data, and the transform can be specified. Here we
use the square root.

The unit hydrograph module in \ihacres{} is a linear \emph{transfer
  function}, i.e. a set of exponentially receding stores, which may be in a
parallel or series configuration. 

We will specify a \emph{second-order} transfer function for the unit
hydrograph, which can be interpreted as two
stores in parallel: ``quick'' flow and ``slow'' flow. This
model structure often works well and is conceptually attractive. Its
notation is $(n=2, m=1)$.

So, to finally calibrate the model:

<<model-fit, echo=TRUE>>=
cotterMod <- update(cotterMod, rfit = list("sriv", order = c(n=2, m=1)))
cotterFit <- fitByOptim(cotterMod)
@

See the help pages \code{help("hydromad")} and
\code{help("fitByOptim")} for details of some of the
options available.


\section{Model Output}

Now that we have an object representing a calibrated model, what can
we do with it?

\begin{description}
\item[access data] \code{fitted(mod)}, \code{residuals(mod)},
  \code{observed(mod)} and \code{getU(mod)}. These exclude the warm-up
  period by default.
\item[simulate] \code{predict(mod, newdata=...)} or
  \code{update(mod, ...)}.
\item[view model info] \code{print(mod)} and \code{summary(mod)}.
\item[get parameter values] \code{coef(mod)}.
\item[plot hydrograph] \code{xyplot(mod)}; see below.
\item[plot flow duration curve] \code{qqmath(mod)}; see below.
\item[plot diagnostics] Some time series diagnostics are available as
  \code{tsdiag(mod)}.
\end{description}

For details, see the examples below, the user manual, and the help
page of each function.\footnote{Note that to get help for generic
  functions it is necessary to specify the method for \code{hydromad}
  objects: e.g. \code{?predict.hydromad} or \code{?xyplot.hydromad}}

View the modelled and observed streamflow time series using
\code{xyplot}, as in Figure \ref{fig:obs-mod-plot}.
Figures \ref{fig:print-hydromad} and \ref{fig:summary-hydromad} show the
output from using the functions \code{print()} and \code{summary()} on
the model object.

\begin{figure}[hpbt]
\begin{center}
<<obs-mod-plot-the70s-code, echo=TRUE, results=hide>>=
xyplot(cotterFit, scales = list(y = list(log = TRUE)))
@
<<obs-mod-plot-the70s, fig=TRUE, height=4>>=
print(trellis.last.object())
@
\caption{\label{fig:obs-mod-plot} Observed vs modelled
  streamflow in the calibration period. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
    \emph{To display information and parameters of a model:}
<<print-model, echo=TRUE>>=
print(cotterFit)
@
\caption{\label{fig:print-hydromad}
  Printing a model to view its parameter values. Note one can get hold of
the parameter values using
\code{coef(cotterFit)} or
\code{coef(cotterFit, which = "routing")} (for the unit hydrograph module).
}
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
\emph{To display basic performance statistics for a model:}
<<summary-model-code, echo=TRUE>>=
summary(cotterFit)
@
\caption{\label{fig:summary-hydromad}
  Calculating basic performance statistics for a model. The
  \code{summary} function actually returns a list, containing the
  values of various performance statistics. }
\end{center}
\end{figure}


\section{Model Simulation}

We can simulate this model on the other periods using the \code{update} function:
<<update-newdata, echo=TRUE>>=
sim70s <- update(cotterFit, newdata = ts70s)
sim80s <- update(cotterFit, newdata = ts80s)
simAll <- update(cotterFit, newdata = Cotter)
@

For \emph{verification} purposes, we would like to calculate
performance statistics for the whole dataset but excluding the
calibration period. The easiest way to do this is to set the
observed streamflow data in the calibration period to \code{NA}
(missing), and then run the simulation:
<<verfication-period-one, echo=TRUE>>=
tsVerif <- Cotter
tsVerif$Q[time(ts90s)] <- NA
simVerif <- update(cotterFit, newdata = tsVerif)
@

It is convenient to group these models together into a
\code{runlist}, which is just a list of models:
<<runlist, echo=TRUE>>=
allMods <- runlist(cotterFit = cotterFit, sim70s = sim70s, sim80s = sim80s,
                   simVerif = simVerif)
@

The predicted time series (hydrograph) and cumulative distribution
(flow duration curve) can be generated as in Figures
\ref{fig:obs-mod-plots} and \ref{fig:fdc-plot}.

\begin{figure}[hpbt]
\begin{center}
<<obs-mod-plots-code, echo=TRUE, results=hide>>=
library(latticeExtra)
xyplot.list(allMods[2:3], trans = log, layout = c(1,2))
@
<<obs-mod-plots, fig=TRUE>>=
print(trellis.last.object())
@
\caption{\label{fig:obs-mod-plots} Observed vs modelled
  streamflow in validation periods. }
\end{center}
\end{figure}


\begin{table}[hpbt]
\begin{center}
<<mod-cal-stats-table-code, echo=TRUE, eval=FALSE>>=
summary(allMods, pars = FALSE)
@
<<mod-cal-stats-table, results=tex>>=
perfstats <- summary(allMods, pars = FALSE)
print(xtable(perfstats), floating = FALSE)
@
\caption{\label{tab:mod-cal-stats} Performance statistics for a set of models. }
\end{center}
\end{table}


\begin{figure}[hpbt]
\begin{center}
<<mod-1990s-summary-table-code, echo=TRUE>>=
print(summary(simAll, breaks = "5 years"), digits = 2)
@
\caption{Viewing a break-down the performance of a model over 5-year blocks. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot performance statistics over time:}
<<r2-breaks-plot-code, echo=TRUE, results=hide>>=
yearStats <- summary(simAll, breaks = "12 months")
statSeries <- zoo(as.matrix(yearStats), as.Date(row.names(yearStats)))
statSeries$r.squared <- pmax(statSeries$r.squared, 0)
c(xyplot(statSeries[,c("r.squared", "r.sq.log")],
       outer = TRUE, type = "s", lwd = 2, ylim = c(0, 1),
       ylab = "statistic", xlab = NULL),
  xyplot(aggregate(Cotter$Q, function(x) as.Date(as.yearmon(x)), mean, na.rm=TRUE)),
  xyplot(simAll, scales = list(y = list(log = TRUE))),
  layout = c(1,4), x.same = TRUE) +
    layer(panel.grid(v=0), under=TRUE) +
    layer(panel.refline(v = time(statSeries)), under=TRUE)
@
<<r2-breaks-plot, fig=TRUE, height=7>>=
print(trellis.last.object())
@
\caption{\label{fig:r2-breaks-plot} The $R^2$ performance statistic
  plotted over time in each 12 month block. The runoff coefficient and
  number of missing values are also shown. See also the function
  \code{errormasscurve()}, which shows the model \emph{bias} over time. }
\end{center}
\end{figure}


\begin{figure}[hpbt]
\begin{center}
  \emph{To plot the flow duration curve for modelled vs observed
    data in the calibration period:}
<<fdc-1-plot-code, echo=TRUE, eval=FALSE>>=
qqmath(cotterFit, scales = list(y = list(log = TRUE)), type=c("l","g"))
@
  \emph{To plot a flow duration curves for each of the simulated models:}
<<fdc-plot-code, echo=TRUE, results=hide>>=
library(latticeExtra)
xyplot.list(allMods, FUN = qqmath,
            type=c("l","g"), scales = list(y = list(log = TRUE)),
            xlab = "Standard normal variate",
            ylab = "Flow (mm/day)", panel = panel.qqmath.tails,
            as.table = TRUE)
@
<<fdc-plot, fig=TRUE, height=7>>=
print(trellis.last.object())
@
\caption{\label{fig:fdc-plot} Log-normal Daily Flow Duration Curve for models in
  simulation. }
\end{center}
\end{figure}


\section{Model and Calibration Options}

There are several extensions to the basic model used so far. With
different types of data, such as very dry or wet catchments, sub-daily
time steps, poor areal rainfall estimates, cases of baseflow loss to
groundwater, etc, different models or calibration methods will need to
be used.


\subsection{Model and Parameter Ranges}

We have used an \ihacres{} CWI model in this tutorial, which is a
metric type model.
Another option for the effective rainfall model is
is CMD (Catchment Moisture Deficit), which is a more
conceptual type model, based on a mass balance equation. See the user
manual for details.

Ranges of parameters to search when calibrating the effective rainfall model
can be specified as arguments to the \code{hydromad} or
\code{update()} functions. Alternatively, parameters can be fixed to
a given value by specifying a single number.

The default ranges can be seen, and set, using \code{hydromad.options()}.

To include the extra parameters \code{l} and/or \code{p}, used for
arid zone catchments, specify ranges. An example:

<<eval = FALSE>>=
hydromad(ts90s, sma = "cwi", l = range(0, 200), f = 0)
@


\subsection{Optimisation}

Argument \code{samples} specifies how many
random parameter sets will be sampled (using the predefined parameter
ranges) to find a good starting point for further optimisation. The
one model with best objective function value is chosen.

The objective function can be set with argument \code{objective}. See
the user manual for examples of different statistics.


\subsection{Transfer Function Order}

The order of the unit hydrograph transfer function may be
varied, as well as the delay time. If there is any ambiguity in
choosing the best delay time, each possibility should be tried.

A recommended approach is to begin with a simple model like $(n=1,
m=0)$, then test whether a more complex model leads to substantial
improvement. Complex models often can not be well identified from
observed data; in this case the calibration may fail to converge, or may
converge to an invalid parameter set.

To test different model structures systematically, a convenience
function \code{tryModelOrders} is provided. An example is given in
Table \ref{tab:try-model-orders}.

For more information on these issues see, for example,
Jakeman et. al. (1990) and Young (2003).

\begin{table}[hpbt]
\begin{center}
<<try-model-orders-table-code, echo=TRUE, results=hide>>=
ihSpec <- hydromad(ts90s, sma = "cwi", routing = "armax", rfit = "sriv")
osumm <- tryModelOrders(fitByOptim(ihSpec),
                        n = 1:3, m = 0:3, delay = 0)
ordersSummary(osumm)
@
<<try-model-orders-table, results=tex>>=
perfstats <- ordersSummary(osumm)
print(xtable(perfstats), floating = FALSE)
@
\caption{\label{tab:try-model-orders}
  Fit and information statistics for different unit hydrograph
  transfer functions.}
\end{center}
\end{table}


\subsection{Unit Hydrograph Fitting Methods}

Another alternative is to fit the unit hydrograph to the observed
streamflow data -- though usually constrained by rainfall -- and then
use that as a fixed component while calibrating the effective rainfall
model. This can be done with \code{rfit = list("inverse", ...)}. (There
are many options here also).

Or specified unit hydrograph parameters can be fitted together with
the SMA parameters (using fitBySampling, etc).


\subsection{Extensions to the Unit Hydrograph}

The unit hydrograph can be extended in two ways. The \emph{lambda}
model allows the partitioning of flow between quick and slow stores to
vary depending on the magnitude (intensity) of effective
rainfall. High intensity events to be dominated by quick flow.

The other extension is a baseflow loss parameter, which specifies a
constant loss of volume from the slow flow component. This will be
generalised in future to vary over time.

See the user manual for details.


\subsection{Other Options}

If model calibration is failing, you can set
\code{hydromad.options(trace = TRUE)} and/or
\code{hydromad.options(catch.errors = FALSE)} to track down what is
happening.

It is sometimes useful to look at the model state variables, available as
\code{predict(mod, return\_state = TRUE)} (for the effective rainfall model), or
\code{predict(mod, return\_components = TRUE)} (for the routing
module), to see if they look sensible.

Some other things to try are
\begin{itemize}
  \item using different calibration periods;
  \item changing the warmup period length;
%  \item using a different prefilter (for \code{"ls"} and
%  \code{"sriv"} fitting methods);
  \item changing the optimisation method and/or settings: see \code{hydromad.options()}.
\end{itemize}


\section{What Next?}

This document has described only a very basic model fitting process.

An overview of the available models and options is given in the user
manual, which can be accessed as \code{vignette("hydromad")}.

Other documents, demonstrating more complex models and advanced
calibration and performance assessment methods, are under development.

Help pages are available for most functions (although some have not
yet been written)... There is also a set of demos: see
\code{demo(package = "hydromad")} for a list.

Discuss any problems with \code{felix.andrews@anu.edu.au} at this
pre-release stage.


\newpage

\section*{Computational details}

The results in this paper were obtained using \proglang{R}
\Sexpr{paste(R.Version()[6:7], collapse = ".")} with the packages
\pkg{hydromad} \Sexpr{gsub("-", "--", packageDescription("hydromad")$Version)},
\pkg{zoo} \Sexpr{gsub("-", "--", packageDescription("zoo")$Version)} and
\pkg{latticeExtra} \Sexpr{gsub("-", "--", packageDescription("latticeExtra")$Version)}.
\proglang{R} itself and all packages used are (or will be) available from
CRAN at \code{http://CRAN.R-project.org/}.


\end{document}
